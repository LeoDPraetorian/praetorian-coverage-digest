## []{#app05.xhtml_page_319 .pagebreak}**E  More Fault Injections** {#app05.xhtml_app05 .h2}

### **E.1 Java Card Invalid Bytecode** {#app05.xhtml_app05_1 .h3}

Java Card is a reduced version of Java intended to run on
micro-controllers and smart cards. It's one of those crazy contraptions
that could only have been invented in the Nineties, allowing Java
development of firmware applets. Here, we'll discuss a type confusion
problem described in Mostowski and Poll (2008) and elsewhere, as well as
a way to glitch past protections in that scheme from Barbu, Thiebeauld,
and Guerin (2010).

Many trade-offs are required to make this work. Within a Java Card
applet, you'll find far more use of primitive types than in regular Java
software. The available libraries are limited, and you absolutely must
do your cryptography by calling hardware acceleration libraries rather
than implementing your own purely in software.

Java Card 3 was released in 2008 with mandatory on-chip byte-code
validation (OCBV). Prior cards simply trust the developer's workstation
to produce and sign only valid bytecode. This means that anyone with
signing authority can simply write illegal byte-code that casts one
class to another, then uses the data fields of the misinterpreted class
to dump all ROM.

While you probably won't have signing keys for a card whose keys you'd
like to extract, it's often possible to buy a "white card" from eBay
that accepts development keys. On these cards, such an exploit can be
used to dump the JVM ROM, a very useful artifact for attacking locked
cards.

::: image
[]{#app05.xhtml_page_320
.pagebreak}![Image](images/f0320-01.jpg){#chEfig1}

> **Description:** Java code snippet showing INS_SEARCH_CLASS case in bytecode manipulation routine. While loop searches for class by incrementing forged reference in memory, converting APDU command bytes to string name using bytesToString and ISO7816.OFFSET_CDATA offset. Code checks if object is Class instance, then verifies name matches by casting and comparing getName() result. Catches SecurityException silently. This demonstrates Java Card applet exploit iterating through memory to locate specific class objects for privilege escalation by manipulating object references.

:::

Figure E.1: Catching a Miscast Instruction

We already mentioned that Java Card 3 closes this loophole, so let's
discuss a trick to perform the type confusion at runtime without
offending the bytecode verifier. It was first described in Barbu,
Thiebeauld, and Guerin (2010).

The idea is to use Java's [try]{.literal}/[catch]{.literal} construct,
in which the error from an illegal cast is caught without crashing the
machine. Very many glitches can be applied, with the applet helping to
cover up those that failed until a lucky one succeeds.

Barbu presents the concrete example from [Figure
E.1](#app05.xhtml_chEfig1), in which the [SecurityException]{.literal}
is quietly caught and ignored, but if the cast does not trigger an
exception, then the cast object is ready for reuse. This will spin
forever without fault injection, because the exception will always
occur, but a lucky fault will skip the exception and allow the cast.
Once successfully cast, the mistyped object can be reused for hours
without triggering another exception.

### []{#app05.xhtml_page_321 .pagebreak}**E.2 L11, M2351, LPC55 CrowRBAR** {#app05.xhtml_app05_2 .h3}

Roth (2019) describes a glitching attack against both NuMicro's M2351
chip and NXP's LPC55S69. This was quickly followed by Results (2020b),
which describes some very practical effects of those glitches. Roth's
paper concerns voltage glitching attacks against the attribution units,
which define the trust levels of regions of memory.

He begins by describing ARM's standardized security attribution unit
(SAU). This is the peripheral that describes regions of memory as
Secure, Non-Secure, or Non-Secure Callable. Some chips also support an
implementation-defined attribution unit (IDAU), which might be custom
rather than inherited from ARM's standard designs.

His first target is Microchip's SAM L11, one of the first chip
microcontrollers to ship with TrustZone-M. This chip does not contain an
SAU, only an IDAU that is configured by the boot ROM from a row in flash
memory.^[1](#footnotes.xhtml_app5fn1){#app05.xhtml_app5fn_1}^

The goal of the fault is to read secure-world data while running from
the non-secure world. Glitching did not trigger the brown out detector
(BOD) peripheral, which was a concern as that peripheral is supposed to
reset the chip when the voltage drops too low.

As he did not yet have a dump of the boot ROM, he had to hypothesize a
good target rather than disassembling to learn the right timing. He used
a ChipWhisperer to reveal that the secure mode is first set at 2.18 ms
after reset; this shows as a gross difference in the power consumption.
A custom firmware image could then be written to immediately reveal the
success or failure of a glitch around that time, narrowing the
parameters before attacking black-box targets.

::: image
[]{#app05.xhtml_page_322
.pagebreak}![Image](images/f0322-01.jpg){#chEfig2}

> **Description:** Die photograph of cryptographic processor or secure element showing sparse logic-dominant architecture. Central area contains large open region with scattered irregular structures suggesting random logic and state machines. Peripheral areas show small memory blocks and interface circuits arranged around edges. The low density of regular structures indicates control-heavy design with minimal memory, typical of cryptographic accelerators or security processors. Sparse layout makes optical analysis challenging but also suggests fewer memory-based secrets vulnerable to extraction.

:::

Figure E.2: Nuvoton M2351

[]{#app05.xhtml_page_323 .pagebreak}The SAM L11 is available as a bare
chip, but also provisioned with a key and Trustonic's Kinibi-M, a
commercial Trusted Execution Environment library. This variant is called
the SAM L11 KPH, and the user is only allowed to write and debug the
non-secure world. Roth purchased some from Digikey and glitched the chip
until OpenOCD reported a successful read, after which he could read out
Knibi for reverse engineering or even replace it for supply chain
attacks.

Roth's second target was the Nuvoton M2351. Unlike the SAM L11, this
chip contains both an SAU and a fixed IDAU. Its marketing explicitly
advertises defenses against voltage glitching.

He first expected glitching this chip to be simple, as the more-secure
opinion of the SAU or IDAU will override the other. Unfortunately for
his attack, this chip uses a special instruction, [blxns]{.literal} or
[bxns]{.literal}, to branch (and link) to the non-secure world from the
secure world.

The last bit of the destination address is also checked by these
instructions. Secure code pointers are odd, which in older chips would
imply the Thumb instruction set. When the secure world wishes to call
the non-secure world, it must first clear a bit of the pointer to be
compatible with these instructions.

Therefore, a minimum attack might be to first glitch the instruction
that sets [SAU-\>CTRL=1]{.literal} and then glitch the bit clear that
precedes [blxns]{.literal} so the normal-world code runs in a
secure-world context. This works, but it is very difficult to make
stable.

Roth's better attack against this chip is called CrowRBAR. The idea here
is that the IDAU maps each region twice, first as secure and again at a
different location as non-secure. Bit 28 distinguishes the mirror, being
set for the secure mapping and clear for the non-secure mapping. The
SAU's [RBAR]{.literal} register then []{#app05.xhtml_page_324
.pagebreak}describes the start of the non-secure region, and if it were
left as zero, the entire region would be non-secure.

Glitching the write of the [RBAR]{.literal} register takes about thirty
seconds, exposing the entirety of the region to the non-secure world!
Roth is unable to read the SAU registers back in this state to know
exactly what the effect of the glitch was, but he is able to read the
entirety of flash memory from code in the non-secure world.

Roth also considered NXP's LPC55S69, whose layout is quite similar to
the M2351. A complication of this target over the M2351 is the
[MISC_CTRL_REG]{.literal} register's [ENABLE_SECURE_CHECKING]{.literal}
field, which checks that the attribution unit's security state matches
that of the memory protection checker (MPC). This can also be glitched,
but only with multiple faults.

While Roth's interest was largely in privilege escalation to the secure
world in these chips, Results (2020b) describes three attacks against
cryptography functions in the M2351's ROM library (MKROM). These attacks
depend upon the fact that non-secure code can expose timing on a GPIO
pin just before a call into the ROM, so the glitcher has very
predictable timing and very little drift.

The first glitches the AES key to zero by skipping
[XAES_SetKey()]{.literal}, advancing the timing by 2.5 µs. The second
glitches the output from [XAES_SetDMATransfer()]{.literal} down to
zeroes.

You will often hear that AES128 or some other algorithm is vulnerable to
cryptanalysis when rounds have been skipped, and when I was younger, I
wondered where the hell that might be useful. The third attack from
Limited Results glitches to skip the last AES round. Feeding two faulted
ciphertexts into Philippe Teuwen's PhoenixAES tool for differential
fault analysis reveals *K*~10~, from which the entire key schedule can
be extracted, including the original AES key as *K*~00~.

### []{#app05.xhtml_page_325 .pagebreak}**E.3 68HC705 and 6805** {#app05.xhtml_app05_3 .h3}

Motorola's 68HC705 is an early 6800 microcontroller with built-in
EEPROM, protected from readout by an option bit that can be bypassed
with glitching. The 6805 is related, but features a mask ROM that can be
photographed and a test mode that can dump the same electrically.

Pemberton (2022) is a custom glitcher built from an Arduino Mega2560 and
an Altera MAX7000S CPLD, the latter being chosen for its 5V I/O pins
that are convenient for working with the old microcontroller. His CPLD
provides 32 MHz (31.25 ns) resolution when glitching the supply voltage
and 2 MHz clock of the target.

Power glitches are applied through either one or four 2N7000 FETs, and
supply current on the 5V rail was limited by a resistor between 10 Ω and
220 Ω.

Pemberton used Motorola (1995) as a handy source of the boot ROM's
source code, but he admits that he resorted to brute-forcing the timing
rather than choosing a target instruction. He describes a nifty trick of
expiring the watchdog timer before pulling the chip out of reset. This
way, the watchdog interrupt does not interfere with the regularity of
the cycle counting.

For both the 68HC705 with EEPROM and the older MC6805 chip with a mask
ROM, there is an undocumented test mode to dump the memory. Riddle
(2016) is mostly about photographically extracting the ROM, but it also
contains this description of an electrical extraction:

::: bq
I was able to electronically dump the ROM using the non-user-mode (NUM)
pin. I used a 1 MHz clock on the EXTAL pin with XTAL grounded, tied
!RST, !INT and TIMER high, and connected NUM to +5. I tied the Port A
pins to +5 and ground using eight 1K resistors to set it to
[0x9D]{.literal}, the opcode for [nop]{.literal}, and I tied Port C.3
high. The ROM contents were output on Port B; I captured the bytes using
a logic analyzer.
:::

::: image
[]{#app05.xhtml_page_326
.pagebreak}![Image](images/f0326-01.jpg){#chEfig3}

> **Description:** Die photograph showing split architecture with distinct memory and logic regions. Upper left quadrant contains large memory block with vertical striping. Central horizontal band has dense control logic and processing circuits. Lower half displays two large memory arrays with vertical striping patterns. Right side shows peripheral circuits and I/O structures. Central vertical line suggests fault injection damage or manufacturing artifact. The symmetric memory layout with central processor represents Harvard architecture vulnerable to bus monitoring between memory and execution units.

:::

Figure E.3: 68HC705C8A

[]{#app05.xhtml_page_327 .pagebreak}Riddle's page describes electrical
dumps of the EEPROM-based MC68705P5 when not secured, which is the same
procedure as above except that Port C.0 is pulled to seven volts through
a 1K resistor. The MC68705P3 and ST Micro's EF6805U3 are the same,
except that they do not have support for securing against electrical
dumping. He notes that dumping often begins at the target of the reset
vector, rather than at address zero.

Please do not confuse his method with the self-test mode, which is a way
to dump a checksum of memory and not its contents. It sits at
[0x784]{.literal} in the ROM of the MC6805P2, where it is activated by
putting nine volts on the TIMER pin, shifting the interrupt vector table
up by eight bytes. LEDs connected with Port C will flash on a checksum
failure.

::: image
[]{#app05.xhtml_page_328
.pagebreak}![Image](images/f0328-01.jpg){#chEfig4}

> **Description:** Die photograph of microcontroller with balanced memory-logic architecture. Left side shows four stacked memory blocks with horizontal striping pattern indicating SRAM or register files. Center region contains complex irregular logic including ALU, control units, and data paths. Right section has two large memory arrays with random texture suggesting flash or EEPROM. Upper and lower areas contain peripheral circuits and interface logic. The clear separation of volatile memory (left), processing (center), and non-volatile storage (right) provides distinct attack targets.

:::

Figure E.4: Game Boy Color CPU

::: image
![Image](images/f0328-02.jpg){#chEfig5}

> **Description:** Assembly code showing memory copy routine with labeled loop structure. Code loads hl with 0 (Begin at 0x0000), de with $a100 as destination. Loop reads byte from [hl] into accumulator, loads e with a value (de is now $a100|a), writes a to $a100|a, increments hl to next address, then jumps back to copy_loop. This routine copies memory contents from ROM starting at address 0x0000 to RAM at 0xa100, demonstrating basic memory dumping technique for firmware extraction.

:::

Figure E.5: Game Boy Color Shellcode from Sideris (2009a)

### []{#app05.xhtml_page_329 .pagebreak}**E.4 Super Game Boy and GB Color** {#app05.xhtml_app05_4 .h3}

While the ROM of the Game Boy (DMG) can be read photographically, as we
saw in [Chapter 23](#ch23.xhtml_ch23), the Super Game Boy and Game Boy
Color have ROMs in which bits are not visible from the surface. Perhaps
Dash etching would expose them, but voltage glitching makes that
unnecessary.

Described in Sideris (2009a) and Sideris (2009b), the trick is to glitch
the final instruction of the ROM, which disables ROM access until the
next reboot. By skipping this instruction, a flash memory cartridge
programmed with code to dump the ROM can freely read the code out of
memory.

Sideris glitches this by having an FPGA replace the CPU's clock and the
cartridge. It counts clock cycles at a normal rate until executing the
lockout instruction at [0x00FE]{.literal}, then halts the clock and
removes power for a few seconds to drain the chip of some state. The
hope is that the internal ROM will not be disabled, and that the CPU
will come back to life at a later address, somewhere in cartridge
memory.

On a successful glitch, the cartridge ROM then executes a long nop sled,
falling into the shellcode in [Figure E.5](#app05.xhtml_chEfig5). That
shellcode reads through all memory, writing to [0xA100\|x]{.literal} for
every byte [x]{.literal} that's read out of memory. Those writes are
silently ignored, but the access log produced by his FPGA then contains
every byte of the console's memory in order.

The Super Game Boy maps its ROM from [0x0000]{.literal} to
[0x00FF]{.literal}, just like a Game Boy. The Game Boy Color has a 3kB
ROM that is mapped into both that region and into the range from
[0x0200]{.literal} to [0x08ff]{.literal}, which overlaps the cartridge
ROM but leaves a gap for the cartridge ROM header from
[0x0100]{.literal} to [0x01FF]{.literal}. It is from within this gap, or
after [0x0900]{.literal}, that shellcode must run.

### []{#app05.xhtml_page_330 .pagebreak}**E.5 STM32F2 Chip.Fail and Kraken** {#app05.xhtml_app05_5 .h3}

Roth, Datko, and Nedospasov (2019) describes a glitch of the STM32F2
boot ROM, used to downgrade from RDP Level 2 (full protection) to Level
1, where flash memory is protected but SRAM is not protected. By
extending this with a second glitch, Uncredited (2020) demonstrates
dumping firmware from a fully locked chip.

Among other details, Roth notes that it is better to time against the
reset pin rising high, rather than the application of power. A shunt
resistor for power analysis shows the reading of the option bytes that
contain the protection mode as the first visible power
spike.^[2](#footnotes.xhtml_app5fn2){#app05.xhtml_app5fn_2}^

Using an FPGA and MAX4619 analog switch, they successfully glitched the
STM32F2 into RDP Level 1 with a delay of 17,900 cycles and a pulse of 50
cycles at 100MHz. RDP Level 1 does not expose flash memory, but early
versions of the Trezor cryptocurrency wallet moved key material into
SRAM, allowing its extraction with careful timing. Grand (2022)
describes using this attack against an old cryptocurrency wallet to
record the otherwise lost contents, as updates are not deployed to
devices forgotten in safes.

Like the RDP downgrade in [Chapter D.3](#app04.xhtml_app04_3), this
glitch can also be used to later extract memory with STM32 exploits that
require RDP Level 1, such as the one in [Chapter 2](#ch02.xhtml_ch02).

Uncredited (2020) begins by reproducing the RDP downgrade glitch from
Roth, Datko, and Nedospasov (2019). Like Roth, he was unable to find a
fault that dropped the chip all the way to Level 0, and he was
interested in dumping secrets that were held only in flash memory and
never copied to SRAM. To do this, he began with some observations.

[]{#app05.xhtml_page_331 .pagebreak}First, he notes that glitching
roughly 170 µs after reset will enable JTAG and SWD on an STM32F205.
Glitching 180 µs after reset will re-enable the bootloader ROM. Both
JTAG/SWD and the ROM behave as if they were in RDP Level 1, but there is
a crucial difference: JTAG and SWD will disable access to flash memory
in hardware when access attempts are made, but the bootloader prohibits
access by a software check that is performed within the command handler.

This means that you can dump flash memory from a locked chip by first
glitching at startup to drop into RDP Level 1, beginning a bootloader
session, and then performing a second glitch during the Read Memory
command handler.

### **E.6 STM8 Bootloader and SWIM** {#app05.xhtml_app05_6 .h3}

The STM8 series of 8-bit microcontrollers are used in automotive
immobilizers and other useful targets. The chip's lock is in the form of
a code readout protection (CRP) bit, which is checked by the bootloader.

There is also a brown out reset (BOR) feature that resets the chip when
the voltage drops beneath a threshold. BOR isn't exactly a glitching
defense, but it might require that any glitches be narrow and well
calibrated to avoid unnecessary resets.

Described in Section 4 of Herrewegen et al. (2020) is a double-glitching
attack on the STM8L152 and STM8AF6266. The first glitch faults a read of
[0x8000]{.literal}, tricking the bootloader into thinking that the chip
is empty, so that the bootloader starts instead of the application. The
second glitch faults a read from [0x4800]{.literal}, tricking the chip
into thinking that CRP is not enabled.

::: image
[]{#app05.xhtml_page_332
.pagebreak}![Image](images/f0332-01.jpg){#chEfig6}

> **Description:** Die photograph of microcontroller showing complex multi-tiered memory architecture. Upper section contains large memory blocks with vertical striping. Central horizontal bands display multiple stacked memory arrays with varying densities and structures. Lower section shows additional memory regions and peripheral circuits. Left and right edges contain interface logic and I/O circuits. The stratified layout with multiple memory types at different levels suggests sophisticated memory hierarchy with cache, RAM, and ROM components. Bond pads around perimeter provide external connections.

:::

Figure E.6: STM8L152

[]{#app05.xhtml_page_333 .pagebreak}Glitching both of these targets is
difficult because there's no feedback mechanism letting you know that
one of them was timed right, until both have successfully been glitched.
There's no way in the locked chip to distinguish a near miss from a
total failure. To remedy this, they patched the bootloader to run from
flash memory, allowing experimentation with partial feedback before
moving to the tricky double-glitch of the locked
chip.^[3](#footnotes.xhtml_app5fn3){#app05.xhtml_app5fn_3}^

A far easier glitching target than the bootloader is the SWIM debugging
interface, which is the STM8's equivalent of JTAG. The STM8S103 was
successfully faulted into an unprotected SWIM session with a single
glitch after reset in Fritsch (2020). This result was reproduced more
recently in Rainier (2022) with nothing more than a pair of high-speed
LMC555 timers! Both reported success when glitching the VCAP pin to
ground with very short pulses.

### **E.7 STM32F1/F3 Shaping the Glitch** {#app05.xhtml_app05_7 .h3}

Two glitching attacks against the STM32 are reported in Bozzato,
Focardi, and Palmarini (2019), in which the authors used a signal
generator to control the shape of each voltage glitch.

Against the STM32F1 series, they report glitching the Read Memory
command to bypass the bootloader's readout protection check. When
successful, this glitched check returns [ACK]{.literal} and a chunk of
memory. Unsuccessful attempts quickly return a [NAK]{.literal} and no
memory, but have no penalty against future attacks.

For the STM32F3, they perform a glitch at reset to downgrade from RDP
Level 2, in which no bootloader or JTAG connections are allowed, down to
RDP Level 1, in which limited bootloader and JTAG access are available
and the chip is vulnerable to other attacks. They note some
complications to the glitch timing, as the boot process takes some time
in which the target's clock drifts away from the glitcher's clock.

[]{#app05.xhtml_page_334 .pagebreak}But why do they glitch into Level 1
instead of all the way to Level 0? Well, Level 2 is defined as
[0xCC33]{.literal} and Level 0 is [0xAA55]{.literal} in the protection
configuration word, so damaging these to *any other value* produces
Level 1. For this reason, glitching all the way to Level 0 is much more
difficult than simply dropping into Level 1.

Other STM32 fault injection attacks follow a similar pattern. Uncredited
(2020) in [Chapter E.5](#app05.xhtml_app05_5), for example, performs its
reads by glitching the protection level check at runtime rather than at
boot time.

### **E.8 MSP430F5172 Glitch Per Word** {#app05.xhtml_app05_8 .h3}

The serial boot-strap loader (BSL) of the MSP430F5 family requires a
password in the form of the firmware's interrupt vector table (IVT)
before the Read command can operate. The general idea is that if you
know the contents of the interrupt table, then you already have a copy
of firmware, so there's nothing for the chip to defend.

It's frustrating to glitch, because the bit that stores the password
comparison success is checked for *every byte* that is read by the TX
Data Block command, but a successful attack is documented in Bozzato,
Focardi, and Palmarini (2019) that dumps individual bytes. This attack
is surprisingly fast once calibrated, nearly two kilobytes per minute.

The authors also implemented this attack on a ferroelectric RAM (FRAM)
device, the MSP430FR5725. FRAM is a potential []{#app05.xhtml_page_335
.pagebreak}replacement for flash memory, but because bit errors are
frequent at the lowest levels, it includes an ECC mechanism to correct
expected bit errors, making an unreliable memory appear rock solid. They
note that this error correction makes the attack much slower, roughly
one kilobyte every six minutes.

### **E.9 CC2640 CC2652 eFuses** {#app05.xhtml_app05_9 .h3}

Wouters, Gielichs, and Preneel (2022) describes a fault injection attack
against the CC2640R2F and CC2652R1F, 2.4GHz radio microcontrollers in
the SimpleLink series by Texas Instruments. Their commercial target was
the Tesla Model 3 key fob, which uses the CC2640.

By reverse engineering a dump of the bootloader ROM, they identified two
good targets for glitching in the form of settings that are fetched from
the Customer Configuration (CCFG) and Factory Configuration (FCFG) pages
of eFuses. To ease experimentation, they built an emulator for the ROM
away from hardware.

They first characterized the glitch width that triggered faults but not
crashes by glitching a tight loop in an artificial target program,
allowing them to temporarily set aside the issue of the glitch offset.
The CC2640R2F (Cortex M3) was best faulted for a duration of 100 ns,
while the CC2652R1F (Cortex M4) was best faulted for a longer duration,
610 ns. They attribute this to differences in micro-architecture.

#### **Customer Configuration (CCFG)** {#app05.xhtml_ch00lev2sec4 .h4}

A first glitching target was the Customer Configuration (CCFG) eFuse
parsing, in which the ROM reads [CCFG:CCFG_TAP_DAP_x]{.literal}
registers to learn which JTAG features will be enabled. Side channel
analysis of power consumption differences between a chip with valid
firmware and a chip with invalid firmware gave an estimated "last
moment" of the ROM parsing CCFG bits. Potential glitch target times were
explored backward from that offset.

::: image
[]{#app05.xhtml_page_336
.pagebreak}![Image](images/f0336-01.jpg){#chEfig7}

> **Description:** Die photograph of large processor showing memory-dominant architecture. Upper left corner has analog circuits including circular structures. Majority of die occupied by extensive memory arrays with horizontal and vertical striping patterns indicating multiple memory types. Lower left contains two prominent circular analog blocks likely PLLs or oscillators. Right half dominated by large regular memory array. Scattered logic blocks throughout indicate control and peripheral functions. The combination of analog blocks and extensive memory suggests mixed-signal microcontroller with substantial storage capacity.

:::

Figure E.7: Texas Instruments CC2640

[]{#app05.xhtml_page_337 .pagebreak}Here they hit a snag: each glitch
attempt might enable JTAG, but JTAG is slow, and they were only able to
attempt one glitch every 2.5 seconds! To speed things up, they wrote a
quick little program that outputs the state of the [JTAGCFG]{.literal}
register to a UART. This allowed glitch timings against a test chip to
be quickly attempted without waiting on a JTAG connection, at a rate of
ten attempts per second. After characterization, the derived glitch
offset from the test chip could then be used on the real target chip.

Measured in 200 MHz ChipWhisperer cycles after reset, the successful
offsets for glitching the CCFG to enable JTAG were between 188,300 and
188,4000 cycles for the CC2640R2F, for a success rate of 5%. The
CC2652R1F was glitched between 161,700 and 162,000 cycles after reset,
with a success rate of 1%.

#### **Factory Test Mode (FCFG)** {#app05.xhtml_ch00lev2sec5 .h4}

By this point, successful glitches were known for both chips, but they
were slow. A better target presented itself in an undocumented factory
test mode, one that is earlier in the boot process and triggered by the
Factory Configuration (FCFG) fuses.

If you recall that the principle limitation of glitching CCFG was
detecting the open JTAG connection, then you might hope for some other
signal that the glitch was successful. The very best such signal would
be a GPIO pin, and that's exactly what was found by reverse engineering
early checks in the ROM.

Checking the GPIO pin state allows one hundred attempts per second, ten
times better than the UART indication. Because the
[]{#app05.xhtml_page_338 .pagebreak}code for the indication exists in
ROM, it works on both practice attempts and against a real target of
unknown firmware!

Successful glitching sets GPIO pin 23 high. The CC2640R2F glitches into
this state between 161,100 and 161,200 cycles after reset, with a glitch
width of 115ns resulting in a 10% success rate. This takes less than a
second! The CC2652R1F glitched into this state between 129,700 and
129,900 clock cycles, but saw no improvement from the earlier glitch
width of 610ns. This had a success rate of 0.1%, allowing them to enable
all debugging features in no more than a few seconds.

### **E.10 LC87 Unlooping over USB** {#app05.xhtml_app05_10 .h3}

One of my favorite sources for this book is Scott (2016). She describes
a glitching attack against the USB [GET_DESCRIPTOR]{.literal} request of
the Sanyo/ONsemi LC871W32 microcontroller in a Wacom CTE-450 tablet. Her
article is a joy to read, ending with a successful read of a 125 kHz
RFID tag using the scanning wires of the tablet and a software-only
memory corruption exploit. For the purposes of this book, I'll focus on
her initial extraction of the device's mask ROM by glitching its USB
handlers.

The LC87 is an 8-bit microcontroller, sold in very high volumes and
without any support for hobbyist or low-volume use. In the case of these
pen tablets, Wacom first used a flash memory variant of the chip and
later switched to a masked ROM variant.

When she first approached the tablet, the debugging port of the LC87
denied any connections and having no serial bootloader, USB was her best
bet for a memory corruption attack.

Back then, there was little in public writing about USB glitching
attacks, so she designed the FaceWhisperer, an extension for
[]{#app05.xhtml_page_339 .pagebreak}Colin O'Flynn's
Chipwhisperer.^[4](#footnotes.xhtml_app5fn4){#app05.xhtml_app5fn_4}^
Like my Facedancer boards, hers uses a Maxim MAX3241E USB controller,
but she also provides a 12MHz clock output and a glitch trigger input
with an adjustable voltage threshold.

While timing the glitch can be harder in USB than against a UART
bootloader, there do exist universal commands implemented by all USB
devices. Rather than target something unique to the Wacom's protocol,
she targeted the generic [GET_DESCRIPTOR]{.literal} handler, which is
implemented in all USB devices. It returns a structure defining the
interfaces and endpoints the device provides. While this structure can
be dynamically generated, many devices simply store a static copy in
code memory and return it when requested.

In the tablet's case, the USB configuration descriptor was 34 bytes long
and returned in a single packet. A successful transaction looks
something like this.

::: imagel
![Image](images/f0339-01.jpg)

> **Description:** Text output showing Reed-Solomon encoded data stream. Line labeled "IN" contains hexadecimal string starting with "09022200010100801E09040000010301020009211..." Line 4 shows "rcode 5 total 34" indicating Reed-Solomon error correction with 5 redundancy symbols across 34 total symbols. This encoding protects data integrity during transmission or storage, but also reveals data structure useful for reverse engineering communication protocols or file formats.

:::

When the timing is just right, a glitch can corrupt the length of the
transfer, causing more bytes to be returned. This example shows 268
bytes, 234 of which come after the 34 bytes of the real descriptor.
After a few more glitches with similar timing, she managed to luck out
with a 65,534-byte transaction, including all 32kB of mask ROM!

::: imagel
[]{#app05.xhtml_page_340 .pagebreak}![Image](images/f0340-01.jpg)

> **Description:** Extended hexadecimal data dump showing IN section with multiple lines of encoded data. Each line contains continuous hex stream without spaces. Bottom line indicates "rcode 5 total 268" showing Reed-Solomon error correction with 5 parity bytes protecting 268 total bytes. The large data block suggests complete message or packet capture, with error correction parameters revealing protocol structure. Pattern analysis of this data stream aids in reverse engineering communication formats or extracting embedded firmware updates.

:::

After dumping the ROM, she reverse engineered it to find an undocumented
backdoor, a human interface device (HID) request that writes exactly 16
bytes into SRAM at an arbitrary address. While RAM is not executable on
this platform, that was enough for her to load and execute a ROP chain
for arbitrary behavior.

With a little analog magic and a lot of experience, she was able to
pulse the tablet's sense wires in the right way, to both power and read
an EM4100 RFID tag. A strange goal, but a damned impressive one,
considering that there were zero hardware modifications in her final
target.

### **E.11 78K0 Glitching Checksums** {#app05.xhtml_app05_11 .h3}

The first glitching exploit of the Renesas 78K0 was described in
Bozzato, Focardi, and Palmarini (2019). Their exploit glitches the
Checksum and Verify commands to operate on four bytes instead of the
minimum 256 bytes.

A later attack in Herrewegen et al. (2020) uses knowledge from a reverse
engineered ROM to provide more accurate timing, leaking individual
bytes. Because the sanity check must be bypassed
[]{#app05.xhtml_page_341 .pagebreak}for every byte read, a successful
dump takes ten hours or so after the equipment has been calibrated.

The best-known attack is well described in Wouters et al. (2020), which
is mostly about the Texas Instruments DST80 immobilizer system for
modern cars. Rather than try to dump firmware from the immobilizer chip,
they glitched a Renesas 78K0/KC2 chip from a Toyota
ECU.^[5](#footnotes.xhtml_app5fn5){#app05.xhtml_app5fn_5}^ And rather
than try to glitch the Checksum or Read commands, Wouters glitches the
Set Security command. This command includes a safety check to ensure
that the new security state is no less secure than the old one, and
bypassing this check allows a single successful glitch to unlock the
chip.

Glitch parameters can be found on [page 105](#ch10.xhtml_page_105) of
their paper, in which a 16 MHz target's Security Set command was
glitched from 2.7V to 0V with a 100 ns width at an offset of 596.78 µs
or 818.05 µs after the first bit of the Security Set message. They
believe the timing difference comes from the choice of protections, as
one of their targets had more protections enabled than the other.

### **E.12 RX65 Bootloader Glitching** {#app05.xhtml_app05_12 .h3}

Renesas RX65 chips allow readout protections to be set for memory ranges
and by installing an ID code. The range restrictions are used to prevent
reading the bootloader ROM, while the ID code is the password that
protects against readout of flash memory.

Julien (2021) describes a voltage glitching attack against the Renesas
RX65N, accomplished by first reverse engineering the undocumented FINE
protocol that wraps commands of the documented serial communication
interface (SCI) protocol. He then removed the target's decoupling
capacitors and glitched through a transistor on the VCL pin, which
exposes the internal core voltage. His glitch pulse was applied by a
Nucleo-F429L board running at 180MHz, and the source pulse was under 100
ns.

[]{#app05.xhtml_page_342 .pagebreak}While his initial glitching was
performed without having a dump of the bootloader ROM, that glitch
allowed him to dump reserved areas of memory. Most returned all zeroes,
but eventually the bootloader ROM was found in the range from
[0xfe7f-9000]{.literal} to [0xfe7fffff]{.literal}. This is a little
weird in that it sits beneath a round number, rather than beginning on a
round number.

### **E.13 GPLB52X Tamagotchi** {#app05.xhtml_app05_13 .h3}

Many Tamagotchi toys use the GPLB52X, an LCD controller from General
Plus with a 6502 microcontroller and an application in custom mask ROM.
Here we'll discuss three ways to get remote code execution inside them
for firmware dumping, and one of these techniques seems portable to
other 6502 machines with attacker-controlled SRAM buffers.

Silvanovich (2013a) describes a reliable software exploit of an
unhandled case in a [switch]{.literal} statement of the Tamatown Tama-Go
toys, with shellcode loaded as artwork into the LCD framebuffer. This
exploit is particularly clever because she had to write it blind,
without already having a dump of the mask ROM to reverse engineer.

Starting with the die photo on [page 343](#app05.xhtml_chEfig8), she
searched through wire-bonding documentation from General Plus until the
bonding pads in the documentation matched those in the chip from the
toy. That told her the chip's model number and allowed her to write
shellcode, but she still needed a way to execute her shellcode.

::: image
[]{#app05.xhtml_page_343
.pagebreak}![Image](images/f0343-01.jpg){#chEfig8}

> **Description:** Die photograph showing mixed architecture with flash memory and logic regions. Upper left contains regular memory arrays and control circuits. Central area dominated by large irregular regions with mottled texture characteristic of flash memory with visible programming patterns. Right lower section displays two large dense memory blocks with horizontal striping. Left side has peripheral circuits and interface logic. The combination of flash storage and structured memory arrays suggests secure microcontroller with firmware storage vulnerable to readout attacks through glitching or voltage manipulation.

:::

Figure E.8: General Plus GPLB52X

::: image
[]{#app05.xhtml_page_344
.pagebreak}![Image](images/f0344-01.jpg){#chEfig9}

> **Description:** Memory map diagram showing address space from 0600 to ffff. Regions include SPU/GP RAM (0600 0000-0000), DPRAM (1fff 1000-1fff), I/O Reg (3000), ROM Bank L (4000), ROM Bank H (8000), Test ROM (c000), and ROM (cc00-ffff). The banked ROM architecture with test ROM section and separate I/O regions reveals typical cartridge-based system memory layout. Test ROM presence suggests development or diagnostic mode vulnerable to exploitation for dumping production ROM contents.

:::

Figure E.9: Simplified GPLB52X Memory Map

[]{#app05.xhtml_page_345 .pagebreak}And executing shellcode is tricky,
as the attacker controls only external EEPROM memory. This external
memory is not executable in place, so it's necessary to wait for the
device to read the external EEPROM and then copy some of its data to
internal SRAM, which is executable. Helpfully, the toy keeps sprites in
the external EEPROM that are displayed on the toy's LCD screen from a
memory-mapped frame buffer.

So she placed shellcode with a long nop sled into the LCD buffer as
plugin graphics from an external EEPROM, then fuzzed all available
configuration bytes in the EEPROM until the shell-code ran and dumped
the internal ROM. Having the ROM, she reverse engineered it to find a
parser vulnerability in a [switch()]{.literal} statement and wrote a
clean exploit that reliably triggered the same code execution with
minimal side effects.

A later toy, Tamagotchi Friends, was released without support for memory
chip accessories or infrared communications, but with support for a
small EEPROM of persistent data and an NFC peripheral. Silvanovich
(2014) describes a successful glitching attack, in which she was able to
redirect execution into her 54-byte shellcode that was copied as data
from EEPROM into the LCD frame buffer.

Rather than trying to skip a specific instruction as many other
glitching attacks do in this book, she instead glitched the target hard
enough that the program counter was corrupted. The 6502 CPU has no
illegal instructions and much of unused memory reads as
[0x00]{.literal}, which is a [brk]{.literal} instruction when a debugger
is attached but otherwise a [nop]{.literal}, forming a nop sled that
leads more or less to her shellcode, shown in [Figure
E.10](#app05.xhtml_chEfig10).

Another example of a brownout glitch can be found in YKT (2023), where
the 6502 core of a Mitsubishi M37409M2 is tricked into running shellcode
from an SRAM buffer. Like Natalie's attack, this one also uses shellcode
with a long nop sled and relies on randomizing the program counter with
a long power fault rather than attempting to glitch an individual
instruction.

::: image
[]{#app05.xhtml_page_346
.pagebreak}![Image](images/f0346-01.jpg){#chEfig10}

> **Description:** Assembly code showing hardware initialization sequence disabling low battery interrupt, configuring port directions, LCD indicator, and memory registers. Code uses SEI, LDA, STA instructions to set up ports $3011, $1109, $00C5, $00C6 and initializes Y register. Comments note "No room to initialize Y. Worst case, it will be set to 0 at the end of the loop" and "These four bytes get altered before execution. Jump over them." followed by five NOP instructions. This reveals tight memory constraints and self-modifying code vulnerable to manipulation.

:::

Figure E.10: GPLB52X (6502) Shellcode for Tamagotchi Friends

[]{#app05.xhtml_page_347 .pagebreak}YKT describes the attack like this:

::: bq
Dumped the SC-55mkII's secondary MCU (Mitsubishi M37409M2) firmware
using voltage glitching. Injecting trojan to its ram and using glitch to
corrupt PC counter to execute it did the trick.

Disabling power of the chip will cause PC register corrupt to randomish
value. Since this is a really simple 8-bit MCU with very small memory
footprint---only 8kB---there's very high chances to point PC to ram
address and execute it after lots of retries.
:::

Silvanovich (2013b) describes a test program, resident in ROM at
[0xC000]{.literal} in the GPLB52X series. Natalie dumped it along with
the Tamagotchi, where it sits just before the application begins at
[0xCC00]{.literal}. See [Figure E.9](#app05.xhtml_chEfig9) for the
memory map and [Table E.1](#app05.xhtml_chEtab1) for a list of test
programs. Test mode is started with the test pin of the die, then the
program number sampled over Port A. She has particular interest in
programs [03]{.literal} and [14]{.literal}.

Program [03]{.literal} is a ROM checksum routine. By default, when Port
B is not set, the checksum covers the entire ROM. Setting Port B allows
a range to be clocked in, but this is sadly not exploitable for dumping
individual bytes. The range must be at least 255, and a bug in the ROM
leaves Port B in input mode after the transaction, so you can't read the
checksum when a limited range is selected.

+--------------------------+--------------------------------------------------------+
| []{#app05.xhtml_page_348 | Sleep mode?                                            |
| .pagebreak}              |                                                        |
|                          |                                                        |
| [00]{.literal}           |                                                        |
+--------------------------+--------------------------------------------------------+
| [01]{.literal}           | RAM Test                                               |
+--------------------------+--------------------------------------------------------+
| [02]{.literal}           | Stress Test                                            |
+--------------------------+--------------------------------------------------------+
| [03]{.literal}           | ROM Checksum                                           |
+--------------------------+--------------------------------------------------------+
| [04]{.literal}           | LCD Test                                               |
+--------------------------+--------------------------------------------------------+
| [05]{.literal}           | Unknown                                                |
+--------------------------+--------------------------------------------------------+
| [06]{.literal}           | Port Stress Test                                       |
+--------------------------+--------------------------------------------------------+
| [07]{.literal}           | Timer Interrupt Test                                   |
+--------------------------+--------------------------------------------------------+
| [08]{.literal}           | Another LCD Test                                       |
+--------------------------+--------------------------------------------------------+
| [09]{.literal}           | Unknown                                                |
+--------------------------+--------------------------------------------------------+
| [0A]{.literal}           | Unknown                                                |
+--------------------------+--------------------------------------------------------+
| [0B]{.literal}           | Something like [09]{.literal}                          |
+--------------------------+--------------------------------------------------------+
| [0C]{.literal}           | Something like [00]{.literal}                          |
+--------------------------+--------------------------------------------------------+
| [0D]{.literal}           | Something like [04]{.literal}                          |
+--------------------------+--------------------------------------------------------+
| [0E]{.literal}           | Unknown                                                |
+--------------------------+--------------------------------------------------------+
| [0F]{.literal}           | SPI Test                                               |
+--------------------------+--------------------------------------------------------+
| [10]{.literal}           | Unknown                                                |
+--------------------------+--------------------------------------------------------+
| [11]{.literal}           | LCD Test                                               |
+--------------------------+--------------------------------------------------------+
| [12]{.literal}           | Something like [16]{.literal}                          |
+--------------------------+--------------------------------------------------------+
| [13]{.literal}           | ROM Checksum                                           |
+--------------------------+--------------------------------------------------------+
| [14]{.literal}           | **Code Execution!**                                    |
+--------------------------+--------------------------------------------------------+
| [15]{.literal}           | Interrupt Test?                                        |
+--------------------------+--------------------------------------------------------+
| [16]{.literal}           | Jumps to RAM at [0x0200]{.literal}                     |
+--------------------------+--------------------------------------------------------+
| [17]{.literal}           | Sets [0x300b]{.literal} and [0x300c]{.literal}         |
+--------------------------+--------------------------------------------------------+

Table E.1: GPLB52X Test Codes from Silvanovich (2013b)

Program [14]{.literal} is more useful. It accepts bits of a program over
port B.7, one bit at a time, with bits 2 and 4 of the same port
signaling when the next bit is ready. The program is loaded from
[0x0200]{.literal} to [0x05ff]{.literal}, then executed in place after
the last bit is loaded. [Figure E.11](#app05.xhtml_chEfig11) has a
listing of this program handler.

::: image
[]{#app05.xhtml_page_349
.pagebreak}![Image](images/f0349-01.jpg){#chEfig11}

> **Description:** Assembly code listing with address, opcode bytes, mnemonics, and operands showing I/O port operations. Code at cab9-cad7 performs SEI, loads immediate values, and stores to portb_dir, portb_conf, portb_data, DAT_0081, DAT_0080. Section labeled "copyloop:" at cad9 implements data transfer using STA, LDA, ASL, ROR, LDX, STX, JSR operations with DAT and port references. Final instructions include INC, CMP, BNE forming loop structure. This port manipulation code represents communication protocol or data exfiltration routine vulnerable to bus monitoring.

:::

Figure E.11: GeneralPlus Test Program [14]{.literal}

### []{#app05.xhtml_page_350 .pagebreak}**E.14 MC9S12 Reset Glitch** {#app05.xhtml_app05_14 .h3}

HCS12 chips such as Freescale's MC9S12 chip are popular as automotive
ECUs. They are regularly cracked by the automotive chip-tuning industry
to adjust the air fuel ratios of fuel injected engines.

Stephen Chavez and Specter presented some hints at their crack in Chavez
and Specter (2017), and from private correspondence I've confirmed that
they dumped the chip by pulling the reset line high with a very short
pulse to confuse the HCS12 reset state machine.

The VVDI Prog is a commercial chip programmer, whose special feature is
built-in support for memory extraction attacks against a number of
automotive microcontrollers, for performance tuning or key copying. As
of version 4.9.5, it advertises attacks against some members of the
MC68HC(9)08, MC68HC(9)12, and MC9S12 families.

### **E.15 Nvidia Tegra X2** {#app05.xhtml_app05_15 .h3}

While the Tegra X1 had a very well-publicized deployment in the Nintendo
Switch, the X2 was found in more expensive devices, such as autonomous
driving units and infotainment systems in modern cars. A voltage fault
injection for the X2 is described in Bittner et al. (2021).

The X2 boots in three stages: (1) the iROM runs from masked ROM to
decrypt and verify the signature of (2) Nvidia's MB1 bootloader from an
eMMC, which then runs (3) the OEM's MB2 bootloader from eMMC. MB1 is
encrypted and its signing key is tightly protected by Nvidia, but MB2
can be freely modified using development kits.

Bittner's first challenge was to write an MB2 image that would dump the
iROM for reverse engineering. This was aided by leaked BootROM source
code from the X1, which periodically appears online before disappearing
in a flurry of DMCA notices.

::: image
[]{#app05.xhtml_page_351
.pagebreak}![Image](images/f0351-01.jpg){#chEfig12}

> **Description:** Compact code snippet showing glitch candidate detection logic. The routine checks device type flags (is_fam, is_ppm, is_not_fam) using conditional branching (bl, cbz, cbnz). Key decision points lead to either NvBootUartDownload or exit paths. Comment annotations explicitly mark two "Glitch candidate" locations where timing-sensitive branches could be exploited through voltage or clock manipulation to bypass authentication checks.

:::

Figure E.12: Fuse Check in the X2's UART Bootloader

Reverse engineering the iROM revealed that the chip supports a "Failure
Analysis Mode," in which a prompt is sent to a UART and then code is
received over that UART for execution. This mode is chosen by a fuse
check early in the boot process, so the fuse check is a good glitch
target. The reset pin can be used as a trigger signal for glitch timing,
and the appearance of a UART prompt indicates a successful glitch.

For the fault injection itself, Bittner used an IRF8736 MOSFET to glitch
a voltage rail of the X2, controlling the MOSFET by an FPGA's GPIO pin
through a MAX4619 level shifter. The target of the glitch is roughly the
code in [Figure E.12](#app05.xhtml_chEfig12), with lines 3 or 11 being
good candidates for the faulted instruction.

Having code execution through the UART bootloader, they then loaded
shellcode that used the X2's internal keys to decrypt the MB1
bootloader.

### []{#app05.xhtml_page_352 .pagebreak}**E.16 Zynq 7000 ROM Dump Glitch** {#app05.xhtml_app05_16 .h3}

The Zynq series from Xilinx combine an ARM CPU with a Xilinx 7-Series
FPGA. They're commonly found in lab equipment, Bitcoin mining rigs, and
anywhere else that a Linux machine and an FPGA are needed in a single
package. The chip boots from a signed image in external memory, such as
a SPI flash chip or an SD card.

The Zynq boot ROM supports signed and encrypted firmware images, making
it a prime target for software exploits, but access to the ROM is
disabled before control is handed over to the application. This makes
reading the ROM difficult, even from an unlocked development kit.

Schretlen (2021b) describes a fault injection technique for dumping the
boot ROM. It requires strapping the PLL_DISABLE pin, and also replacing
some of the decoupling caps with SOT23 FETs. Timing was too
unpredictable when triggering on the target's reset signal, and the SD
card's own timing was too noisy to use as a start trigger.

The solution was to trigger after the last byte returned from the SD
card to the Zynq. The author notes that the SPI flash boot method might
be more deterministic, but the required pins were not broken out on the
available development board.

Glitching is a fine way to extract a ROM when there are no other
options, as was the case for the first extraction of this ROM. After
getting the ROM and reverse engineering it, a common goal is to find a
software bug that allows for extraction without glitching. See [Chapter
A.10](#app01.xhtml_app01_10) for just such an exploit against this chip.

### []{#app05.xhtml_page_353 .pagebreak}**E.17 STM32 Body Biasing Injection** {#app05.xhtml_app05_17 .h3}

Body biasing injection (BBI) attacks were first introduced to literature
in Maurine et al. (2012), as a way to induce a fault by regionally
raising the voltage on the underside of the microchip die. This requires
exposing the backside of the die, then stepping a probe around to
explore the best injection spots for any particular attack.

While it requires more equipment and preparation than voltage glitching,
it has the advantage of inducing a *localized* fault. These faults are
confined to a region of the chip, leaving the rest of the chip to run
properly.

O'Flynn (2020b) describes a practical attack against the STM32-F415 in
wafer-level chip-scale packaging (WLCSP), which naturally exposes the
backside of the die. Recall from [Chapter 18](#ch18.xhtml_ch18) that
WLCSP works by putting BGA solder balls directly onto a die, which is
soldered to a circuit board without any plastic encapsulation. This
dramatically reduces the preparation time, as there's no need to
chemically or mechanically remove the device packaging.

He used a custom probe called the ChipJabber BBI that sits at the end of
a ChipWhisperer. Whenever the CW glitch fires, a low-voltage pulse from
two capacitors fires through a transformer to send a high-voltage pulse
into a probe on the backside of the die. Power is provided by a bench
supply with current limiting capability. See [Figure
E.13](#app05.xhtml_chEfig13).

O'Flynn used a three-axis motorized stage and a spring-loaded probe to
scan 256 unique points on the WLCSP package's surface. On these
packages, the surface layer faces downward into the circuit board, while
the backside is exposed away from the board for the probe. Some of them
have a thin opaque layer over the backside, but such paint can be
scraped away with a knife.

::: image
[]{#app05.xhtml_page_354
.pagebreak}![Image](images/f0354-01.jpg){#chEfig13}

> **Description:** Simplified FET glitching circuit schematic showing high-voltage pulse generation. Input signal connects through resistors (62.5kΩ, 62.5kΩ) to dual capacitors (5μF, 5μF) at 5kV, coupled to an IRF850DT MOSFET in center. The FET drives target injection into target (backside) and target (thin) points. Output stage uses Q2 (2N3906) transistor with resistor network (10kΩ) providing controlled voltage injection for fault injection attacks.

:::

Figure E.13: ChipJabber BBI Schematic

::: image
![Image](images/f0354-02.jpg){#chEfig14}

> **Description:** Die photograph of integrated circuit with visible memory arrays and logic blocks. Large dense memory region occupies left side with regular cell structure. Upper center shows rectangular memory blocks with horizontal routing channels. Lower portion contains glitch-vulnerable test points marked as white/light spots, potential targets for fault injection. Right side features vertical memory banks and scattered logic regions with bond pads around perimeter.

:::

Figure E.14: STM32F103 Bias Points from Balda (2021)

[]{#app05.xhtml_page_355 .pagebreak}The transformer was custom-wound
around a commercial ferrite rod, with six turns of 26 AWG magnetic wire
for the primary winding and sixty turns of 30 AWS wire for the secondary
winding. Fewer turns result in lower inductance, which is necessary for
a fast reaction time. More turns would slow the slew rate and lengthen
the pulse duration.

In terms of faults, he was more interested in providing a convenient
target for research into body biasing techniques than breaking the
readout protection of any particular device. His examples include a
nested loop for characterization, a classic fault attack on RSA-CRT and
the beginnings of characterizing faults in the hardware AES accelerator.

As O'Flynn's excellent paper set up the STM32 as a target but stopped
just short of a memory extraction exploit, there was a good opportunity
for a second paper. Balda (2021) provided this, reproducing the work
against an STM32F103 microcontroller with an aim to extract locked
firmware.

His STM32F103 is a wire-bonded BGA in which the front side of the die
faces away from the board and the backside faces down into the board.
This is far less convenient than the WLCSP package, but luckily the
center pins of the BGA package weren't needed for the bootloader. Balda
slowly ground through the PCB, the solder bumps, and the bottom of the
BGA package to reveal the die. A copper pad that was against the die was
pulled away with a scalpel after pieces had been freed by grinding.

This chip has a single RDP level, as we saw in [Chapter
11](#ch11.xhtml_ch11), and Balda chose to attack it through the
bootloader rather than through JTAG. Each time the read request is sent
to the boot-loader as [0x11 0xEE]{.literal}, the BBI fault injection has
a chance to skip the device's RDP check and allow the read to continue.

Balda notes that successful glitches for the RDP bypass were inserted
8.95 µs after the last rising edge of the bootloader read
[]{#app05.xhtml_page_356 .pagebreak}command. The fault must be performed
for every memory read, but a 60% success rate keeps things moving
quickly.

Plotting the successful locations of those faults produces [Figure
E.14](#app05.xhtml_chEfig14), showing that at these voltages the useful
faults all come in or around the flash memory. None of the faults
targeted the CPU, and Balda hypothesizes that this is because the ROM
boot-loader reads from the flash memory's [FLASH_OBR]{.literal}
register, which holds a single bit for the RDP status.

Glitches 3.5 µs after the last rising edge of the command had a
different and undesired effect, mass erasing all flash memory and
destroying the information that might be retrieved. Effects like these
are why it's so important to carefully calibrate glitches, rather than
adopting a "spray and pray" strategy and leaving the equipment to run
unattended in a cupboard.

### **E.18 PCF7941 Erasure** {#app05.xhtml_app05_18 .h3}

NXP has a series of wireless security transponders implemented as RISC
microcontrollers. One of these, the PCF7941, has been successfully
glitched to program replacement car keys.

In a San Francisco dive bar, I heard that this required cooling the chip
with alcohol and dry ice for several days before an FPGA was able to
glitch the 2Link debugging protocol into an unlock. It sounded like the
attack used a single glitch to unlock all the chip at one time, but I'm
not entirely sure from the description.

Some commercial tools, like VVDI Prog mentioned in [Chapter
E.14](#app05.xhtml_app05_14), support the PCF7941. They use a wired
connection to glitch the chip, erasing it for a new pairing. The glitch
is only to allow erasure of a locked chip. These tools don't seem to
extract the firmware, as their customers are more interested in matching
keys to new vehicles.

::: image
[]{#app05.xhtml_page_357
.pagebreak}![Image](images/f0357-01.jpg){#chEfig15}

> **Description:** Full die photograph showing complete chip layout with symmetrical design. Four large vertical memory arrays dominate the center with characteristic striped patterns. Peripheral bond pads line all four edges for external connections. Left and right sides contain control logic and interface circuits. Upper region shows compact logic blocks while lower section displays additional memory structures. Multiple ground and power regions visible as darker rectangular areas throughout the die.

:::

Figure E.15: NXP PCF7941

### []{#app05.xhtml_page_358 .pagebreak}**E.19 EFM32WG without a Brownout** {#app05.xhtml_app05_19 .h3}

The EFM32WG is a nice little ARM Cortex-M chip from Silicon Labs. Its
longevity is guaranteed until 2026, marketed toward smart meters and
industrial automation. While the CPU itself would be vulnerable to
glitching, the chip features effective brownout detection (BOD) circuits
that reset the chip during bootloader glitching attempts, frustrating
the attack.

Results (2021a) describes using electromagnetic fault injection (EMFI)
to glitch the CPU region of the chip, allowing protected firmware to be
read without causing a brownout. This was performed because regular
voltage glitching reliably triggered one of four brownout detectors
(BODs) before introducing any faults, requiring the localized fault
injection that EMFI can provide.

The EMFI system is a custom one called Der Injektor. The design has not
yet been published as I write this, but it might be by the time you read
this.

These results were successfully reproduced by Transistor (2023) against
a Bosch smart home system. While Limited Results built a custom EMFI
tool, Vegan Transistor preferred to modify a Langer BS 06DB-s pulse
generator that was intended for electrical fast transient (EFT) pulse
testing.

To identify the proper time for fault injection, power was traced in
both a locked and an unlocked state. This was performed by a magnetic
field probe near a decoupling capacitor, amplified to account for the
low power consumption of the chip. The glitch target window begins 150
µs after reset, lasting for 47 µs. Immediately afterward, the first
instruction begins execution.

Faults that were too strong triggered a reset, and by backing up just a
bit until the resets ceased, the right power level was identified.
Eventually JTAG unlocked and a standard Segger J-Flash read out 128kB of
firmware.

### []{#app05.xhtml_page_359 .pagebreak}**E.20 MPC55 by EMFI** {#app05.xhtml_app05_20 .h3}

O'Flynn (2020a) describes an electromagnetic attack against the boot
assist module (BAM) of the NXP MPC5676R and MPC5566 chips, PowerPC
devices that are popular in automotive ECUs.

Electrically, the only thing special about an automotive grade chip is
that it will run at a higher temperature. From a security perspective,
though, there's an entire industry called *chip tuning* that hacks these
chips in order to improve engine performance.

It's worth noting that O'Flynn didn't bother reverse engineering the BAM
ROM, as it wasn't necessary to implement his attack. Power rail
glitching would likely also work, but EMFI allows the attack to be
performed without relocating the chip from its board in the ECU of a
2019 Chevy Silverado. There's no need to remove decoupling capacitors or
solder in a transistor for glitching.

Similar chips are sold by as the SPC57xx and SPC58xx from ST Micro.
These perform their permission check *after* buffering the code in SRAM.
That dramatically slows the fault timing search, because the full
transfer must be repeated for every single fault injection attempt.
O'Flynn has not yet reported success in breaking
them.[]{#app05.xhtml_page_360 .pagebreak}

[]{#app06.xhtml}

